---
title: "Lab Exercises 2"
format: pdf
editor: visual
---

```{r}
library(opendatatoronto)
library(tidyverse)
library(stringr)
library(skimr) # EDA
library(visdat) # EDA
library(janitor)
library(lubridate)
library(ggrepel)
```

```{r}
res <- list_package_resources("996cfe8d-fb35-40ce-b569-698d51fc683b") # obtained code from searching data frame above
res <- res |> mutate(year = str_extract(name, "202.?"))
delay_2022_ids <- res |> filter(year==2022) |> select(id) |> pull()

delay_2022 <- get_resource(delay_2022_ids)

# make the column names nicer to work with
delay_2022 <- clean_names(delay_2022)
```

```{r}
delay_2022 <- delay_2022 |> 
  mutate(station_clean = ifelse(str_starts(station, "ST"), word(station, 1,2), word(station, 1)))
```

## Question 1

```{r}
# Calculate the mean delay for each station and line
mean_delays <- delay_2022 |>
  group_by(station_clean, line) |>
  summarise(mean_delay = mean(min_delay, na.rm = TRUE)) |>
  ungroup()

# Find the top five stations with the highest mean delays
top_stations <- mean_delays |>
  arrange(desc(mean_delay)) |>
  slice_max(order_by = mean_delay, n = 5)

# Plot the data, faceting by line
ggplot(top_stations, aes(x = station_clean, y = mean_delay, fill = line)) +
  geom_col() +
  facet_wrap(~ line) +
  labs(title = "Top 5 Stations with Highest Mean Delays",
       x = "Station",
       y = "Mean Delay (minutes)")
```

## Question 2

```{r}
top_50 <- delay_2022 |>
  filter(min_delay > 0) |>
  group_by(code) |>
  summarise(count = length(code)) |>
  arrange(-count) |>
  mutate(cumulative_sum = cumsum(count))|>
  filter(cumulative_sum <= tail(cumulative_sum,1)/2) |>
  select(code)

top_50
```

```{r}
filtered_data <- delay_2022 |>
  filter(min_delay > 0 & (code %in% top_50$code))

filtered_data
```

```{r}
model <- lm(min_delay~as.factor(line) + as.factor(code), data=filtered_data)
```

```{r}
summary(model)
```

Based on the fitting result, most of the coefficients are statistically significant, but only lineYU is not. The r-squared and adjusted r-squared both are around 16.5% which is very low.

The result from the Question 1 shows that every station other than GUNN in YU line has a smaller mean delay time than the ones in BD. This consequence is aligned with the negative coefficient of lineYU.

## Question 3

```         
```

```         
```

```{r}
# Step 1: Find the ID code for the package related to 'campaign'
package_results <- search_packages("campaign")
campaign_package_id <- package_results$id[1]  # Assuming the first result is the correct one

# Step 2: Get the ID for the specific data file
resources <- list_package_resources(campaign_package_id)
mayoral_campaign_resource_id <- resources$id[3]

# Step 3: Download the data file
mayoral_campaign_data <- get_resource(mayoral_campaign_resource_id)[[2]]
```

```{r}
colnames(mayoral_campaign_data) <- as.character(mayoral_campaign_data[1,])
mayoral_campaign_data <- mayoral_campaign_data[-1,]

rownames(mayoral_campaign_data) <- NULL
mayoral_campaign_data <- clean_names(mayoral_campaign_data)

mayoral_campaign_data
```

## Question 4

There are some variable containing a bunch of missing values which can make the model distorted. After dropping the variables with the missing values, the resulting data set involves 7 columns as a result.

```{r}
noMissing <- function(x) all(!is.na(x))

mayoral_campaign_data <- mayoral_campaign_data |>
  select(where(noMissing))

mayoral_campaign_data

```

The contributor_type_desc and contributon_type_desc should be a categorical variable, so we need to change the format to a factor, instead of just character. The contribution_amount should be a numerical variable, so we need to change the format to a numeric, instead of character.

```{r}
mayoral_campaign_data$contributor_type_desc <- as.factor(mayoral_campaign_data$contributor_type_desc)

mayoral_campaign_data$contribution_type_desc <- as.factor(mayoral_campaign_data$contribution_type_desc)

mayoral_campaign_data$contribution_amount <- as.numeric(mayoral_campaign_data$contribution_amount)

mayoral_campaign_data

```

## Question 5

The amount of contribution is gathered in the middle, and does not seem having too many outliers.

```{r}
mayoral_campaign_data |>
  ggplot() +
  geom_density(aes(x = contribution_amount), bw = .08) +
  scale_x_log10()
```

To explore the extreme values area, we need to sort the contribution amount.

```{r}
mayoral_campaign_data |>
  arrange(-contribution_amount)
```

Here is the density of the contribution amount over 2,500.

```{r}
mayoral_campaign_data |>
  filter(contribution_amount>2500) |>
  ggplot() +
  geom_density(aes(x = contribution_amount), bw = .08) +
  scale_x_log10()
```

There a couple of donors who contributed multiple times, such as Ford Doug or Ford Rob. In addition, most of the cases are the monetary contribution and individual donors.

```{r}
mayoral_campaign_data |>
  filter(contribution_amount>2500)
```

## Question 6

```{r}
candidate_contribution <- mayoral_campaign_data |>
  group_by(candidate) |>
  summarise(
  total = sum(contribution_amount, na.rm = TRUE),
  mean = mean(contribution_amount, na.rm = TRUE),
  count = n()
)
```

```{r}
candidate_contribution |>
  arrange(-total) |>
  select(candidate, total) |>
  head(5)
```

```{r}
candidate_contribution |>
  arrange(-mean) |>
  select(candidate, mean) |>
  head(5)
```

```{r}
candidate_contribution |>
  arrange(-count) |>
  select(candidate, count) |>
  head(5)
```

## Question 7

```{r}
non_candidate_contribution <- mayoral_campaign_data |>
  filter(contributors_name != candidate)
  
non_candidate_contribution <- non_candidate_contribution |>
  group_by(candidate) |>
  summarise(
  total = sum(contribution_amount, na.rm = TRUE),
  mean = mean(contribution_amount, na.rm = TRUE),
  count = n()
  )
```

```{r}
non_candidate_contribution |>
  arrange(-total) |>
  select(candidate, total) |>
  head(5)
```

```{r}
non_candidate_contribution |>
  arrange(-mean) |>
  select(candidate, mean) |>
  head(5)
```

```{r}
non_candidate_contribution |>
  arrange(-count) |>
  select(candidate, count) |>
  head(5)
```

## Question 8

```{r}
multiple_contribution <- mayoral_campaign_data |>
  group_by(contributors_name) |>
  summarise(unique_candidates = n_distinct(candidate))
```

```{r}
sum(multiple_contribution$unique_candidates > 1)
```
